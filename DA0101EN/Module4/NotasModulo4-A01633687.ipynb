{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4940715",
   "metadata": {},
   "source": [
    "<h3>Alumno: Daniela Parra Garc√≠a</h3>\n",
    "<h3>Matricula: A01633687</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7d98e8",
   "metadata": {},
   "source": [
    "# Notes Module 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251795d3",
   "metadata": {},
   "source": [
    "**Linear Regression:**<br>\n",
    "One independent variable to make a predition<br>\n",
    "<br>\n",
    "**Multiple Linear Regression:**<br>\n",
    "Multiple independent variables to make a predition<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "**Simple Linear Regression (SLR):**<br>\n",
    "Method that helps understand the relationship between two variables<br>\n",
    "x -> predictor (independent) variable<br>\n",
    "y -> target (dependent) variable<br>\n",
    "y = b0 + b1 x<br>\n",
    "b0 -> the intercept<br>\n",
    "b1 -> the slope<br>\n",
    "<br>\n",
    "Fitting a Simple Linear Regression:<br>\n",
    "The output is an array with the yhat values and the original x input<br>\n",
    "from sklearn.linear_model import LinearRegression<br>\n",
    "lm = LinearRegression()<br>\n",
    "x=df[['columnName1']]<br>\n",
    "y=df[['columnName2']]<br>\n",
    "lm.fit(x, y)<br>\n",
    "Yhat = lm.predict(x)<br>\n",
    "<br>\n",
    "Get the intercept: (b0)<br>\n",
    "lm.intercept_ <br>\n",
    "<br>\n",
    "Get the slope: (b1)<br>\n",
    "lm.coef_<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "**Multiple Linear Regression:(MLR)**<br>\n",
    "Used to explaon the relationship between one continuous target and two or more predictor variables.<br>\n",
    "y = b0 + b1x1+ + b2x2 + b3x3 + b4x4<br>\n",
    "b0 -> the intercept (x=0)<br>\n",
    "b1 -> the coefficient or parameter of x1<br>\n",
    "b2 -> the coefficient or parameter of x2<br>\n",
    "b3 -> the coefficient or parameter of x3<br>\n",
    "b4 -> the coefficient or parameter of x4<br>\n",
    "<br>\n",
    "Fitting the Multiple Linear Regression:<br>\n",
    "The input will be an array with 4 columns, the number of rows depends on the number of samples. <br>\n",
    "The output is an array with the same number of elements as number of samples<br>\n",
    "z = df[['columnName1', 'columnName2', 'columnName3', 'columnName4']]<br>\n",
    "lm.fit(z, df['columnName0'])<br>\n",
    "Yhat = lm.predict(x)<br>\n",
    "<br>\n",
    "Get the intercept: (b0)<br>\n",
    "lm.intercept_ <br>\n",
    "<br>\n",
    "Get the coefficients: (b1,b2,b3,b4)<br>\n",
    "lm.coef_<br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd82766",
   "metadata": {},
   "source": [
    "**Regression Plot**<br>\n",
    "Are good estimate of:<br>\n",
    "The relationship between two variables<br>\n",
    "The strength of the correlation<br>\n",
    "The direction of the relationship (positive or negative)<br>\n",
    "<br>\n",
    "The horizontal axis is the independent variable<br>\n",
    "The vertical axis is the dependent variable<br>\n",
    "<br>\n",
    "How to use Regression Plot:<br>\n",
    "import seaborn as sns\n",
    "sns.regplot(x='columnNameOfDependentVariableOrFeature', y='columnNameOfDependentVariableOrTarget', data=dataframe)<br>\n",
    "example: sns.regplot(x='highway-mpg', y='price', data=df)<br>\n",
    "plt.ylim(0,)<br>\n",
    "\n",
    "\n",
    "**Residual Plot:**\n",
    "import seaborn as sns<br>\n",
    "sns.residplot(df['dependentVariableOrFeature'], df['dependentVariableOrTarget'])<br>\n",
    "example: sns.residplot(df['highway-mpg'], df['price'])<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "**Distribution Plots:**<br>\n",
    "import seaborn as sns<br>\n",
    "ax1 = sns.distplot(df['dependentVariableOrTarget'], hist=False, color=\"r\", label=\"Actual Value\")<br>\n",
    "hist= False -> we want a distribution instead of a histogram<br>\n",
    "color = \"r\" -> the color is red<br>\n",
    "label=\"Actual Value\" -> the label for the distribution plot<br>\n",
    "example: sns.distplot(df['price'], hist=False, color=\"r\", label=\"Actual Value\")<br>\n",
    "<br>\n",
    "sns.distplot(Yhat, hist=False, color=\"b\", label=\"Fitted Values\", ax = ax1)<br>\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506049a3",
   "metadata": {},
   "source": [
    "**Polynomial Regression and Pipelines:**<br>\n",
    "<br>\n",
    "Polynomial Regressions:<br>\n",
    "A special case of the general linear regression model. It is useful for describing curvilinear relationships.<br>\n",
    "<br>\n",
    "Curvilinear relationships:<br>\n",
    "It is what you get by squaring or setting higher-order terms of the predictor variables.<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "Calculate Polynomial of 3rd order:<br>\n",
    "f = np.polyfit(x,y,3)<br>\n",
    "p = np.poly1d(f)<br>\n",
    "\n",
    "\n",
    "Polynomial Regression with more than one dimension:<br>\n",
    "Numpy cannot perform regressions with complex two-dimensional second order polynomial.<br>\n",
    "We use PolynomialFeatures:<br>\n",
    "from sklearn.preprocessing import PolynomialFeatures<br>\n",
    "pr = PolynomialFeatures(degree=2, include_bias=False)<br>\n",
    "x_poly = pr.fit_transform(x['columnName1', 'columnName2'])<br>\n",
    "<br>\n",
    "Normalize the each feature simultaneously:<br>\n",
    "from sklearn.preprocessing import StandardScaler<br>\n",
    "SCALE = StandardScaler()<br>\n",
    "SCALE.fit(x_data[['columnName1', 'columnName2']])<br>\n",
    "x_scale = SCALE.transform(x_data[['columnName1', 'columnName2']])<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "**Pipelines:**<br>\n",
    "How to create a pipeline that normalizes the data, performs a polynomial transform and then outputs a prediction:<br>\n",
    "from sklearn.preprocessing import PolynomialFeatures<br>\n",
    "from sklearn.linear_model import LinearRegression<br>\n",
    "from sklearn.preprocessing import StandardScaler<br>\n",
    "<br>\n",
    "from sklearn.pipeline import Pipeline<br>\n",
    "<br>\n",
    "Input = [ ('scale', StandardScaler()),  ('polynomial', PolynomialFeatures(degree=2), ('model', LinearRegression()) ]<br>\n",
    "pipe = Pipeline(Input)<br>\n",
    "pipe.fit(x['columnName1', 'columnName2', 'columnName3', 'columnName4'], y)<br>\n",
    "yhat = pipe.predict(x[['columnName1', 'columnName2', 'columnName3', 'columnName4']])<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003a376b",
   "metadata": {},
   "source": [
    "**Measures for In-Sample Evaluation:**<br>\n",
    "\n",
    "Two important measures to determine the fit of a model:<br>\n",
    "Mean Squared Error (MSE)<br>\n",
    "R-squared (R2)<br>\n",
    "<br>\n",
    "**Mean Squared Error (MSE)**<br>\n",
    "from sklearn.metrics import mean_squared_error<br>\n",
    "mean_squared_error(df['columnName'], Y_predict_simple_fit)<br>\n",
    "\n",
    "\n",
    "**R-squared (R2)**<br>\n",
    "x = df['columnName1']\n",
    "y = df['columnName2']\n",
    "lm.fit(x,y)\n",
    "lm.score(x,y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afcc31b",
   "metadata": {},
   "source": [
    "**Do the predicted values make sense:**<br>\n",
    "\n",
    "import numpy as np<br>\n",
    "new_input = np.arange(1,101,1).reshape(-1,1)<br>\n",
    "yhat = lm.predict(new_input)<br>\n",
    "\n",
    "Methods:<br>\n",
    "1. Use a Regression plot to visualize your data\n",
    "2. Examine the Residual Plot\n",
    "3. Examine the Distribution Plot in case of a Multiple Linear Regression\n",
    "4. The Mean Square Error is the most intuitive numerical measure (graph it for better visualization)\n",
    "5. Use the R-squared (graph it for better visualization)\n",
    "6. Comparing MLR and SLR \n",
    "<br>Lower MSE not necessarily implies a better fit.<br>\n",
    "MSE for an MLR model will be smaller than the MSE for an SLR model, since the errors of the data will decrease when more variables are included in the model.<br>\n",
    "Polynomial regression will also have a smaller MSE than regular regressions.<br>\n",
    "A similar inverse relationship holds for R-squared.<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0876294",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
